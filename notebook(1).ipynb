{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02eb72b4-2016-45ed-b802-7160e7a12fb8",
    "_uuid": "a5ca4610fc731fc7f706e4d1a0327b58f9f8748b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4d33acec-ffca-4f0f-a81b-73ff5076a218",
    "_uuid": "f591804eb063669d8307a79610493aaffe7b9e46",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train= pd.read_table('../input/train.tsv',engine= 'c')\n",
    "test= pd.read_table('../input/test.tsv',engine= 'c')\n",
    "tr_rows = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "858e0909-d974-4e2e-b8ab-ae1e077262ee",
    "_uuid": "ebe923fd29654e07f6a6957159a1acdd8c6de952",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train,test],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36e9ffd6-ce1f-4e5c-befc-7aa0454a0d07",
    "_uuid": "c97184fbd181f1fe91cf5efcdfdda91347e9d8f0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape,train.shape, test.shape, test.shape[0]/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "127d2304-3742-465a-9557-c90932d5c34d",
    "_uuid": "292848ef80ec0259361862528b62326019bbab4f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7dc10dfd-7648-4eec-838a-0974fd22080b",
    "_uuid": "225d89df84ac7c6bb83f32bf8e67244db2bd2b31",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Handling missing values...\")\n",
    "def handle_missing(dataset):\n",
    "    dataset.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    return (dataset)\n",
    "\n",
    "df = handle_missing(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26f12685-10ab-41d0-a2e0-602b67d1e92e",
    "_uuid": "bd264b4446c35091527b92a4ea0f10a1f857f5e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df= 10)\n",
    "cv.fit(np.hstack([df.name.str.lower()]))\n",
    "X_name_df = cv.transform(df.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "216825c2-63de-4775-8711-ba98ac15af6e",
    "_uuid": "9122c17b09e9ce7ef2363094f5405262d9ebb204",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_name_df = X_name_df.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41c47fc1-23ff-4f93-9268-ce39eda9e806",
    "_uuid": "eee1a3e8cf6b0a543aabb65dee4614d1183f778a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(max_features=10000,\n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words='english')\n",
    "df_item_description = tv.fit_transform(df['item_description'])\n",
    "print(\"tfidf done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a69d245d-0309-49dd-8dea-5d8d1946f963",
    "_uuid": "73beee9b8ad6a3f5b605ae69d92dd10816c9cff6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "y = hstack((X_name_df,df_item_description)).tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88a4dc8c-b140-4e8a-8e36-45ab15c6362f",
    "_uuid": "20d60057295e600c7506b893bfbf5296920a8245",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer(sparse_output= True)\n",
    "lb.fit(df.brand_name)\n",
    "brand_df = lb.transform(df.brand_name)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5dd91d94-abe5-4b24-a529-c9e66f5bbac0",
    "_uuid": "52f77659c4ccd8ec77a8113425a994aa579b31e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies = csr_matrix(pd.get_dummies(df[['item_condition_id', 'shipping']],\n",
    "                                          sparse=True).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da1cd19a-77a3-47ea-b321-e4a9c0438ff4",
    "_uuid": "5468f7568e94d1cd177923f97befbcdb3d49374c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''category split'''\n",
    "\n",
    "dfcat = df['category_name'].str.split('/', expand=True)\n",
    "dfcat.columns = ['cat{}'.format(x+1) for x in dfcat.columns]\n",
    "\n",
    "dfcat= dfcat.drop([\"cat4\",\"cat5\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c771ac3-3582-44af-b8ca-46f5cb54f849",
    "_uuid": "7e6435ee4cd2db81f4ceab1167cec90c98ea3b01",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_missingcat(dataset):\n",
    "    dataset.cat1.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.cat2.fillna(value=\"missing\", inplace=True)\n",
    "    dataset.cat3.fillna(value=\"missing\", inplace=True)\n",
    "    return (dataset)\n",
    "\n",
    "dfcat = handle_missingcat(dfcat)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "df_category1 = cv.fit_transform(dfcat['cat1'])\n",
    "df_category2 = cv.fit_transform(dfcat['cat2'])\n",
    "df_category3 = cv.fit_transform(dfcat['cat3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a150cc42-5ffc-4fed-b248-1e437536e887",
    "_uuid": "7c87cf2a2587cefae0f5012640aa1831cc074187",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sparse_merge = hstack((df_dummies, y, brand_df, df_category1, df_category2, df_category3)).tocsr()\n",
    "print('data processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3e8f0566-39d7-4299-a1c0-3d6db8464532",
    "_uuid": "52525bf089512e19a1b9314c052c33659ba488c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_df = np.log1p(df[\"price\"])\n",
    "train_df = df_sparse_merge[:tr_rows,:]\n",
    "test_df = df_sparse_merge[tr_rows:,:]\n",
    "y_train = y_df[:tr_rows]\n",
    "y_test = df['price'][tr_rows:].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "print('splitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ad4bcf2e-fd99-4486-932a-f47a522fe073",
    "_uuid": "60e69ae7f39a15aa72e73d8a50e666d210f7bdc1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = train_df\n",
    "#train2 = train_df[900000:]\n",
    "target1 = y_train\n",
    "#target2 = y_train[900000:]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train1, target1, test_size = 0.15, random_state = 144) \n",
    "d_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\n",
    "d_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\n",
    "watchlist = [d_train, d_valid]\n",
    "params = {\n",
    "    'learning_rate': 0.65,\n",
    "    'application': 'regression',\n",
    "    'max_depth': 3,\n",
    "    'num_leaves': 60,\n",
    "    'verbosity': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'data_random_seed': 1,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'nthread': 4\n",
    "}\n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=4000, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=1000, verbose_eval=1000) \n",
    "predsL = model.predict(train1)#result 0.7\n",
    "tpredsL = model.predict(test_df)\n",
    "print(\"lgb done\")\n",
    "#ridge\n",
    "\n",
    "model2 = Ridge(alpha=.9, copy_X=True, fit_intercept=True, max_iter=100,normalize=False, random_state=101, solver='auto', tol=0.01)\n",
    "model2.fit(train1, target1)\n",
    "predsR = model2.predict(train1)\n",
    "tpredsR = model2.predict(test_df)\n",
    "print(\"R1 done\")\n",
    "from xgboost import XGBRegressor\n",
    "model3 = XGBRegressor(n_jobs = -1)\n",
    "model3.fit(train1,target1)\n",
    "predsX = model3.predict(train1)\n",
    "tpredsX = model3.predict(test_df)\n",
    "print(\"xgb done\")\n",
    "model4 = Ridge(solver=\"sag\", fit_intercept=True, random_state=205)\n",
    "model4.fit(train1,target1)\n",
    "predsR2 = model4.predict(train1)\n",
    "tpredsR2 = model4.predict(test_df)\n",
    "print(\"R2 done\")\n",
    "ensem = 0.1*(predsL)\n",
    "#rmsle(y_test,(y_pred+np.expm1(predsR2))/2)\n",
    "ensem += 0.4*(predsR)\n",
    "ensem  += 0.1*(predsX)\n",
    "ensem  += 0.4*(predsR2)\n",
    "ensemt = 0.1*(tpredsL)\n",
    "ensemt += 0.4*(tpredsR)\n",
    "ensemt  += 0.1*(tpredsX)\n",
    "ensemt  += 0.4*(tpredsR2)\n",
    "train_for_next = pd.DataFrame([predsR2,predsR,predsL,predsX,ensem]).transpose()\n",
    "test_for_next = pd.DataFrame([tpredsR2,tpredsR,tpredsL,tpredsX,ensemt]).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4ce18ad-d483-4bc9-bdb9-7fe2b681df8f",
    "_uuid": "41925999ebf11bb1fed0d65507ccb87e10557036",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_for_next_scaled = np.zeros(train_for_next.shape)\n",
    "test_for_next_scaled = np.zeros(test_for_next.shape)\n",
    "train_for_next_scaled_sin = np.zeros(train_for_next.shape)\n",
    "test_for_next_scaled_sin = np.zeros(test_for_next.shape)\n",
    "train_for_next_scaled_cos = np.zeros(train_for_next.shape)\n",
    "test_for_next_scaled_cos = np.zeros(test_for_next.shape)\n",
    "for i in range(5):\n",
    "    train_for_next_scaled[:,i] = sc.fit_transform(train_for_next.iloc[:,i].reshape(-1,1))[:,0]\n",
    "    test_for_next_scaled[:,i] = sc.fit_transform(test_for_next.iloc[:,i].reshape(-1,1))[:,0]\n",
    "    train_for_next_scaled_sin[:,i] = np.sin(train_for_next_scaled[:,i])\n",
    "    test_for_next_scaled_sin[:,i] =  np.sin(test_for_next_scaled[:,i])\n",
    "    train_for_next_scaled_cos[:,i] = np.cos(train_for_next_scaled[:,i])\n",
    "    test_for_next_scaled_cos[:,i] =  np.cos(test_for_next_scaled[:,i])\n",
    "NN_train = np.hstack((np.asmatrix(train_for_next_scaled),np.asmatrix(train_for_next_scaled_sin),np.asmatrix(train_for_next_scaled_cos))) \n",
    "NN_test = np.hstack((np.asmatrix(test_for_next_scaled),np.asmatrix(test_for_next_scaled_sin),np.asmatrix(test_for_next_scaled_cos))) \n",
    "\n",
    "finalxg = XGBRegressor(n_jobs = -1)\n",
    "finalxg.fit(NN_train,target1)\n",
    "y_pred_nn = finalxg.predict(NN_test)\n",
    "y_pred = np.expm1(y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9515a1f-33e0-4be2-9a2d-1c84f935f793",
    "_uuid": "241e2c0c509ffa536a7cd98a46b6ec02392f7d01",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv',engine = 'c')\n",
    "submission['price'] = y_pred\n",
    "print(\"submitting...\")\n",
    "submission.to_csv('ensemblerrlxdt.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
